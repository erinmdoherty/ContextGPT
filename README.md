# ContextGPT

**ContextGPT** is an AI-powered document retrieval and answering system. It enables users to upload documents, retrieve relevant context, and generate AI-powered responses using Ollama. The system uses **ChromaDB** as a persistent vector database for efficient document search and retrieval.

## Features
- ğŸ“‚ **Upload PDFs** and store document embeddings for retrieval.
- ğŸ” **Retrieve relevant context** from stored documents using ChromaDB.
- ğŸ¤– **Generate AI-powered answers** using an Ollama-backed inference service.
- ğŸ–¥ï¸ **Simple HTML frontend** for seamless interaction.
- ğŸ³ **Fully containerized with Docker** for easy deployment.

---

## Deployment Instructions

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/nelabdiel/contextgpt.git
cd contextgpt
```

### **2ï¸âƒ£ Install Dependencies**
Ensure Python 3.11+ is installed, then run:
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Start Services Without Docker**
You can manually start each service by running the following in separate terminals:
```bash
cd document_service && python document_service.py
```
```bash
cd retrieval_service && python retrieval_service.py
```
```bash
cd inference_service && python inference_service.py
```
```bash
cd frontend_service && python frontend_service.py
```
Now, open your browser and go to **[http://localhost:5000](http://localhost:5000)**

### **4ï¸âƒ£ Start With Docker (Recommended)**
Ensure **Docker** and **Docker Compose** are installed, then run:
```bash
docker-compose up --build
```
This will build and start all services in the background.

### **5ï¸âƒ£ Access the Frontend**
Once running, open your browser and go to:
ğŸ‘‰ **[http://localhost:5000](http://localhost:5000)**

---

## ğŸ› ï¸ Project Structure
```
/project-root
â”‚â”€â”€ docker-compose.yml        # Manages all services in Docker
â”‚â”€â”€ frontend_service/         # Handles UI & routes requests to backend services
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ frontend_service.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ index.html        # Updated HTML frontend
â”‚â”€â”€ document_service/         # Handles PDF uploads & vector storage
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ document_service.py
â”‚   â”œâ”€â”€ uploads/              # Stores uploaded PDFs
â”‚   â”œâ”€â”€ chroma_db/            # Persistent ChromaDB storage
â”‚â”€â”€ retrieval_service/        # Retrieves relevant text from vector DB
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ retrieval_service.py
â”‚â”€â”€ inference_service/        # Calls Ollama for AI-generated answers
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ inference_service.py
â”‚â”€â”€ requirements.txt          # Shared dependencies
â”‚â”€â”€ README.md                 # Project documentation
```

---

## ğŸ–¥ï¸ API Endpoints
### ğŸ“‚ **Document Service (Port 5001)**
- **Upload PDFs** â†’ `POST http://localhost:5001/upload`
- **Check status** â†’ `GET http://localhost:5001/status`

### ğŸ” **Retrieval Service (Port 5002)**
- **Retrieve relevant text** â†’ `POST http://localhost:5002/retrieve`

### ğŸ¤– **Inference Service (Port 5003)**
- **Generate AI response** â†’ `POST http://localhost:5003/ask`

### ğŸ–¥ï¸ **Frontend Service (Port 5000)**
- **Main UI** â†’ `GET http://localhost:5000/`

---

## ğŸ”„ Stopping and Restarting
To stop all containers:
```bash
docker-compose down
```
To restart with fresh logs:
```bash
docker-compose up --build
```

For manual (non-Docker) deployment, stop services using `CTRL+C` in each terminal window.



